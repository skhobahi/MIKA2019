{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 非凸関数(多数の極小値)において、学習型勾配法の振る舞いを見る\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/wadayama/MIKA2019/blob/master/Egg.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なパッケージをインポートする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## グローバル定数の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_val = 0.01 #学習可能スッテプサイズパラメータの初期値\n",
    "mbs = 50 # ミニバッチサイズ\n",
    "itr = 10 # 勾配法の反復回数\n",
    "adam_lr = 0.0005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目的関数の定義\n",
    "\n",
    "Egg Crate function (卵ケースのような形状をした非凸関数。多数の極小点を持つ)\n",
    "http://benchmarkfcns.xyz/benchmarkfcns/eggcratefcn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    # Egg Crate Function\n",
    "    return x[:,0]**2 + x[:, 1]**2 + 25.0*(torch.sin(x[:,0])**2 + torch.sin(x[:,1])**2) \n",
    "\n",
    "solution = torch.tensor([[0.0, 0.0]]).repeat(mbs,1) # 大域最適解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 勾配ベクトルの計算（数値微分を利用)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_numerical_f(x, bs):\n",
    "    eps = 1e-5\n",
    "    ret = torch.tensor([[0.0  , 0.0]]).repeat(bs,1)\n",
    "    h1  = torch.tensor([[eps, 0.0]]).repeat(bs,1)\n",
    "    h2  = torch.tensor([[0.0,   eps]]).repeat(bs,1)\n",
    "    ret[:,0] = (f(x+h1) - f(x))/eps\n",
    "    ret[:,1] = (f(x+h2) - f(x))/eps\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TGD クラス (Trainable Gradient Descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TGD(nn.Module):\n",
    "    def __init__(self, num_itr):\n",
    "        super(TGD, self).__init__()\n",
    "        self.gamma = nn.Parameter(init_val*torch.ones(num_itr))\n",
    "    def forward(self, num_itr, bs):\n",
    "        traj = []\n",
    "        s = (torch.rand(bs, 2)*20.0 - 10.0)\n",
    "        traj.append(s)\n",
    "        for i in range(num_itr):\n",
    "            s = s - self.gamma[i] * grad_numerical_f(s, bs)\n",
    "            traj.append(s)\n",
    "        return s, traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TGD(itr)\n",
    "opt   = optim.Adam(model.parameters(), lr=adam_lr)\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練ループ(インクリメンタルトレーニング）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gen in range(itr):\n",
    "    for i in range(1000):\n",
    "        opt.zero_grad()\n",
    "        x_hat,_ = model(gen + 1, mbs)\n",
    "        loss  = loss_func(x_hat, solution)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    print(gen, loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 普通の勾配法を定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GD(nn.Module):\n",
    "    def __init__(self, num_itr):\n",
    "        super(GD, self).__init__()\n",
    "    def forward(self, num_itr, bs, gamma):\n",
    "        traj = []\n",
    "        s = (torch.rand(bs, 2)*20.0 - 10.0)\n",
    "        traj.append(s)\n",
    "        for i in range(num_itr):\n",
    "            s = s - gamma * grad_numerical_f(s, bs)\n",
    "            traj.append(s)\n",
    "        return s, traj\n",
    "gd_model = GD(itr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 誤差のプロット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## trained TGD model\n",
    "bs = 10000\n",
    "solution = torch.tensor([[0.0, 0.0]]).repeat(bs,1)\n",
    "\n",
    "with torch.no_grad(): # 評価時は計算グラフの作成を抑制するようにする\n",
    "    for i in range(1): \n",
    "        norm_list = []\n",
    "        itr_list = []\n",
    "        for i in range(itr):\n",
    "            s_hat,_ = model(i, bs)\n",
    "            err = (torch.norm(solution - s_hat)**2).item()/bs\n",
    "            norm_list.append(math.log10(err))\n",
    "            #norm_list.append(err)\n",
    "            itr_list.append(i)\n",
    "        plt.plot(itr_list, norm_list, color=\"red\", label=\"TGD\",marker='o')\n",
    "\n",
    "## normal GD\n",
    "\n",
    "for i in range(1):\n",
    "    norm_list = []\n",
    "    itr_list = []\n",
    "    for i in range(itr):\n",
    "        s_hat, _ = gd_model(i, bs, 0.04)\n",
    "        err = (torch.norm(solution - s_hat)**2).item()/bs\n",
    "        norm_list.append(math.log10(err))\n",
    "        #norm_list.append(err)\n",
    "        itr_list.append(i)\n",
    "    plt.plot(itr_list, norm_list, color=\"green\", label=\"GD (gamma = 0.04)\",marker='o')\n",
    "\n",
    "for i in range(1):\n",
    "    norm_list = []\n",
    "    itr_list = []\n",
    "    for i in range(itr):\n",
    "        s_hat, _ = gd_model(i, bs, 0.09)\n",
    "        err = (torch.norm(solution - s_hat)**2).item()/bs\n",
    "        norm_list.append(math.log10(err))\n",
    "        #norm_list.append(err)\n",
    "        itr_list.append(i)\n",
    "    plt.plot(itr_list, norm_list, color=\"blue\", label=\"GD (gamma = 0.09)\",marker='o')    \n",
    "    \n",
    "for i in range(1):\n",
    "    norm_list = []\n",
    "    itr_list = []\n",
    "    for i in range(itr):\n",
    "        s_hat, _ = gd_model(i, bs, 0.16)\n",
    "        err = (torch.norm(solution - s_hat)**2).item()/bs\n",
    "        norm_list.append(math.log10(err))\n",
    "        #norm_list.append(err)\n",
    "        itr_list.append(i)\n",
    "    plt.plot(itr_list, norm_list, color=\"orange\", label=\"GD (gamma = 0.16)\",marker='o')\n",
    "\n",
    "    \n",
    "#plt.title(\"Error curves\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"log10 of squared error\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\gamma$ をプロットしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = model.gamma\n",
    "gval = g.detach().numpy()\n",
    "gval = gval[0:itr]\n",
    "ind = np.linspace(0,itr-1,itr)\n",
    "plt.plot(ind, gval,marker='o')\n",
    "plt.xlabel(\"index t\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目的関数の等高線プロットの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj(x):\n",
    "    x0 = x[0]\n",
    "    x1 = x[1]\n",
    "    y = x0**2 + x1**2 + 25.0*(math.sin(x0)**2 + math.sin(x1)**2)\n",
    "    return y\n",
    "def plot_contour():\n",
    "    x_0 = np.arange(-10., 10., 0.05)\n",
    "    x_1 = np.arange(-10., 10., 0.05)\n",
    "    X_0, X_1 = np.meshgrid(x_0, x_1)\n",
    "    Y =np.zeros((len(x_0),len(x_1)))\n",
    "    for i in range(len(x_0)):\n",
    "       for j in range(len(x_1)):\n",
    "           X = np.array([X_0[i][j],X_1[i][j]])\n",
    "           Y[i][j] = obj(X)\n",
    "    plt.grid()                          # グリッドの表示\n",
    "    plt.contour(X_0, X_1, Y, 10)         # 10は等高線の本数\n",
    "    plt.gray()                     \n",
    "    plt.gca().set_aspect('equal',adjustable='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索軌跡をプロット (学習型勾配法)\n",
    "\n",
    "* ステップサイズが変動していっている\n",
    "* 当初は探訪を積極的に行う$(\\gamma \\simeq 0.15)$\n",
    "* 最後は小さい$\\gamma$$(\\gamma \\simeq 0.05)$に切り替えて、収束を目指す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 5\n",
    "bs = 1\n",
    "plot_contour()\n",
    "for i in range(num_trials):\n",
    "    s_hat,traj = model(itr, bs)\n",
    "    t0 = []\n",
    "    t1 = []\n",
    "    for s in traj:\n",
    "        t0.append(s[0,0].item())\n",
    "        t1.append(s[0,1].item())\n",
    "    plt.title(\"TGD\")\n",
    "    plt.plot(t0,t1,'o-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索軌跡をプロット (普通の勾配法$\\gamma = 0.04$)\n",
    "\n",
    "* 小さいステップサイズ設定を行うと容易に極小値にトラップされることがわかる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1\n",
    "plot_contour()\n",
    "for i in range(num_trials):\n",
    "    s_hat,traj = gd_model(itr, bs, 0.04)\n",
    "    t0 = []\n",
    "    t1 = []\n",
    "    for s in traj:\n",
    "        t0.append(s[0,0].item())\n",
    "        t1.append(s[0,1].item())\n",
    "    plt.title(\"GD, gamma=0.04\")\n",
    "    plt.plot(t0,t1,'o-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索軌跡をプロット (普通の勾配法$\\gamma = 0.09$)\n",
    "\n",
    "* ほどほどのステップサイズ設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1\n",
    "plot_contour()\n",
    "for i in range(num_trials):\n",
    "    s_hat,traj = gd_model(itr, bs, 0.09)\n",
    "    t0 = []\n",
    "    t1 = []\n",
    "    for s in traj:\n",
    "        t0.append(s[0,0].item())\n",
    "        t1.append(s[0,1].item())\n",
    "    plt.title(\"GD, gamma=0.09\")\n",
    "    plt.plot(t0,t1,'o-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索軌跡をプロット (普通の勾配法$\\gamma = 0.016$)\n",
    "\n",
    "* ステップサイズの設定が大きいと極小値へのトラップは少なくなる\n",
    "* 積極的な解空間の探訪\n",
    "* しかし、収束が望めない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1\n",
    "plot_contour()\n",
    "for i in range(num_trials):\n",
    "    s_hat,traj = gd_model(itr, bs, 0.16)\n",
    "    t0 = []\n",
    "    t1 = []\n",
    "    for s in traj:\n",
    "        t0.append(s[0,0].item())\n",
    "        t1.append(s[0,1].item())\n",
    "    plt.title(\"GD, gamma=0.16\")\n",
    "    plt.plot(t0,t1,'o-')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
